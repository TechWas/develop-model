{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QTS-o98kTOi"
      },
      "source": [
        "# Transfer Learning with Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpgwNbfekkqL",
        "outputId": "ea7b26a1-aba4-4fbc-dd3f-853896f1ac45"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "# !gdown \"https://drive.google.com/uc?id=1dIxJQ8G5GlxV5tb3meBk88QC6gk-rpzC\" -O dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES-H41YJpZnx",
        "outputId": "89b8ae30-a221-40af-978b-79145c82e2f0"
      },
      "outputs": [],
      "source": [
        "# download test dataset\n",
        "# !gdown \"https://drive.google.com/uc?id=15VGocJ8uCQaagg5_nyDIoenGOFfeVSxR\" -O test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o33V6Y-epEgj",
        "outputId": "5c466b3d-4944-40f9-c4de-0436af0f6107"
      },
      "outputs": [],
      "source": [
        "# !rm -r dataset\n",
        "# !rm -r test\n",
        "# !unzip dataset.zip -d dataset\n",
        "# !unzip test.zip -d test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z60XmeoIkTOk"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnc7ZHw0kTOl",
        "outputId": "0b123a2a-c22a-4a3d-874e-6f42c44b0ed8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# avoid error\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Model Hypertunning\n",
        "# !pip install -q keras_tuner\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsO1aSmzkTOl"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fIlP-TVNkTOm"
      },
      "outputs": [],
      "source": [
        "train_data_dir = 'Dataset/train & validation'\n",
        "test_data_dir = 'Dataset/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1g1sfmokTOm"
      },
      "source": [
        "### Preview Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FUkMgVuikTOm"
      },
      "outputs": [],
      "source": [
        "# print(\"Sample day image:\")\n",
        "# plt.imshow(load_img(f\"{os.path.join(day_dir, os.listdir(day_dir)[0])}\"))\n",
        "# plt.show()\n",
        "\n",
        "# print(\"\\nSample night image:\")\n",
        "# plt.imshow(load_img(f\"{os.path.join(night_dir, os.listdir(night_dir)[0])}\"))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEDbI4G_13UR"
      },
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PQYLBFFIkTOm"
      },
      "outputs": [],
      "source": [
        "# Get all class names and count the number of classes\n",
        "class_names = os.listdir(train_data_dir)\n",
        "n_classes = len(class_names)\n",
        "\n",
        "# Set some constants for the dataset\n",
        "BATCH_SIZE = 32 # Number of samples in each batch during training\n",
        "IMAGE_SIZE = 224 # Size of the image\n",
        "# AUTOTUNE = tf.data.AUTOTUNE # Set to optimize the buffer size automatically\n",
        "LEARNING_RATE = 1e-3 # Learning rate for the optimizer used during model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IWIQE1VE1zYS"
      },
      "outputs": [],
      "source": [
        "# Set the random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvAsTzTckTOm"
      },
      "source": [
        "### Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUhoaba_kTOm",
        "outputId": "a5642a9a-04fe-4f7a-9470-210216d992a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                #    rotation_range=40,\n",
        "                                #    width_shift_range=0.2,\n",
        "                                #    height_shift_range=0.2,\n",
        "                                #    shear_range=0.2,\n",
        "                                #    zoom_range=0.2,\n",
        "                                #    horizontal_flip=True,\n",
        "                                #    fill_mode='nearest'\n",
        "                                validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxQFRZnskTOn",
        "outputId": "19d70dd1-e58c-49e5-ac25-2eb45487aaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4023 images belonging to 13 classes.\n",
            "Found 1000 images belonging to 13 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set up the data generator for training and validation\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                         target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         class_mode='categorical',\n",
        "                                                         subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52uxT2gvkTOn"
      },
      "source": [
        "## Modelling and Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZd9vFomkTOo",
        "outputId": "e1640c82-d321-44fa-b1f2-d49e9394a719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 203s 2us/step\n"
          ]
        }
      ],
      "source": [
        "# # Add your custom layers on top of the pre-trained model\n",
        "xception = tf.keras.applications.Xception(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "                                          weights='imagenet',\n",
        "                                          include_top=False)\n",
        "\n",
        "# Freeze the model weights\n",
        "xception.trainable = True\n",
        "\n",
        "# model = Sequential([\n",
        "#     xception,\n",
        "#     GlobalAveragePooling2D(),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(n_classes, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(\n",
        "#     # loss='sparse_categorical_crossentropy',\n",
        "#     loss='categorical_crossentropy',\n",
        "#     optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# model.fit(\n",
        "#     train_generator,\n",
        "#     validation_data=validation_generator, \n",
        "#     epochs=50, \n",
        "#     callbacks=[\n",
        "#         EarlyStopping(patience=3, restore_best_weights=True),\n",
        "#         ModelCheckpoint(\"XceptionModel.h5\", save_best_only=True)\n",
        "#     ],\n",
        "#     batch_size=BATCH_SIZE\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y09iOSmi2w9w"
      },
      "outputs": [],
      "source": [
        "# # best_test_loss, best_test_acc = best_xception.evaluate(X_test, y_test)\n",
        "# # print(f\"Test Loss after Tunig     : {best_test_loss} | {xtest_loss}\")\n",
        "# # print(f\"Test Accuracy after Tunig : {best_test_acc}  | {xtest_acc}\")\n",
        "\n",
        "# xtest_loss, xtest_acc = model.evaluate(test_generator)\n",
        "# print(f\"Xception Baseline Testing Loss     : {xtest_loss}.\")\n",
        "# print(f\"Xception Baseline Testing Accuracy : {xtest_acc}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p_ba31lG0pNN"
      },
      "outputs": [],
      "source": [
        "def build_model(hp, n_classes=13):\n",
        "    \n",
        "    # Define all hyperparms\n",
        "    n_layers = hp.Choice('n_layers', [0, 2, 4])\n",
        "    dropout_rate = hp.Choice('rate', [0.2, 0.4, 0.5, 0.7])\n",
        "    n_units = hp.Choice('units', [64, 128, 256, 512])\n",
        "    \n",
        "    # Mode architecture\n",
        "    model = Sequential([\n",
        "        xception,\n",
        "        GlobalAveragePooling2D(),\n",
        "    ])\n",
        "    \n",
        "    # Add hidden/top layers \n",
        "    for _ in range(n_layers):\n",
        "        model.add(Dense(n_units, activation='relu', kernel_initializer='he_normal'))\n",
        "    \n",
        "    # Add Dropout Layer\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer = Adam(LEARNING_RATE),\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Return model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwox9Xz-0blw",
        "outputId": "3b7c7c93-55b9-4926-ebfc-1f9a607ea23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |2                 |n_layers\n",
            "0.2               |0.2               |rate\n",
            "128               |128               |units\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 790s 6s/step - loss: 0.8223 - val_loss: 3.8184\n",
            "Epoch 2/10\n",
            "126/126 [==============================] - 770s 6s/step - loss: 0.4567 - val_loss: 1.5514\n",
            "Epoch 3/10\n",
            "126/126 [==============================] - 773s 6s/step - loss: 0.3654 - val_loss: 2.6150\n",
            "Epoch 4/10\n",
            "126/126 [==============================] - 811s 6s/step - loss: 0.3195 - val_loss: 0.7968\n",
            "Epoch 5/10\n",
            "126/126 [==============================] - 867s 7s/step - loss: 0.2723 - val_loss: 1.0445\n",
            "Epoch 6/10\n",
            " 56/126 [============>.................] - ETA: 7:18 - loss: 0.1972"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\danie\\OneDrive\\Documents\\GitHub\\try-transfer-learning\\transfer_learning_Xception_Tuning.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m random_searcher \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mRandomSearch(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hypermodel\u001b[39m=\u001b[39mbuild_model, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Start Searching\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m search \u001b[39m=\u001b[39m random_searcher\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m BATCH_SIZE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Documents/GitHub/try-transfer-learning/transfer_learning_Xception_Tuning.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    238\u001b[0m     ):\n\u001b[0;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    251\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize Random Searcher\n",
        "random_searcher = kt.RandomSearch(\n",
        "    hypermodel=build_model, \n",
        "    objective='val_loss', \n",
        "    max_trials=10, \n",
        "    seed=42, \n",
        "    project_name=\"XceptionSearch\", \n",
        "    # loss='sparse_categorical_crossentropy'\n",
        "    loss='categorical_crossentropy'\n",
        ")\n",
        "\n",
        "# Start Searching\n",
        "search = random_searcher.search(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs = 10,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qaphs0yW3XGm"
      },
      "outputs": [],
      "source": [
        "# Collect the best model Xception Model Architecture obtained by Random Searcher\n",
        "best_xception = build_model(random_searcher.get_best_hyperparameters(num_trials=1)[0])\n",
        "\n",
        "# Model Architecture\n",
        "best_xception.summary()\n",
        "\n",
        "# Compile Model\n",
        "best_xception.compile(\n",
        "    # loss='sparse_categorical_crossentropy',\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(LEARNING_RATE*0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model Training\n",
        "best_xception_history = best_xception.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs = 50,\n",
        "    batch_size = BATCH_SIZE*2,\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=2, restore_best_weights=True),\n",
        "        ModelCheckpoint(\"BestXception.h5\", save_best_only=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "loss, accuracy = best_xception.evaluate(test_generator)\n",
        "print(f\"Test Loss after Tunig     : {loss}\")\n",
        "print(f\"Test Loss after Tunig     : {accuracy}\")\n",
        "# print(f\"Test Loss after Tunig     : {loss} | {xtest_loss}\")\n",
        "# print(f\"Test Accuracy after Tunig : {accuracy}  | {xtest_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Ve_WMXkTOo"
      },
      "source": [
        "### Pre-Trained Model Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7oRmGMy21Lo"
      },
      "outputs": [],
      "source": [
        "#  Load model \n",
        "best_xception = tf.keras.models.load_model('/BestXception.h5', compile=False)\n",
        "best_xception.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9EZHmkPkTOp"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-kl0r4UkTOq"
      },
      "outputs": [],
      "source": [
        "def plot_graghs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC2MDXhMkTOq"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdFE7PCjkTOq"
      },
      "outputs": [],
      "source": [
        "plot_graghs(best_xception_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAG4sJpkkTOq"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L54IWfUmkTOr"
      },
      "outputs": [],
      "source": [
        "plot_graghs(best_xception_history, 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8ssdc0MkTOr"
      },
      "source": [
        "## Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WO1ykOFkTOr"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from keras.utils import load_img, img_to_array\n",
        "\n",
        "# label = ['battery', 'cable', 'e_kettle', 'keyboard', 'laptop', 'light_bulb', 'monitor', 'mouse', 'pcb', 'phone', 'printer', 'rice_cooker', 'tv']\n",
        "# for fn in os.listdir('test'):\n",
        "#   path = './test' + fn\n",
        "#   img = load_img(path, target_size=(150, 150))\n",
        "#   x = img_to_array(img)\n",
        "#   x /= 255\n",
        "#   x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#   images = np.vstack([x])\n",
        "#   classes = model.predict(images, batch_size=10)\n",
        "#   print(fn)\n",
        "#   for i, l in zip(classes[0], label):\n",
        "#     print(\"{} : {:.2%}\".format(l, i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk9fYQDHkTOr"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_roUEGfkTOs"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "# model.save('e_waste_classifier.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
