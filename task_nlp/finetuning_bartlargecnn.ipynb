{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output as cls","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:42:38.141050Z","iopub.execute_input":"2023-05-26T05:42:38.141446Z","iopub.status.idle":"2023-05-26T05:42:38.155110Z","shell.execute_reply.started":"2023-05-26T05:42:38.141420Z","shell.execute_reply":"2023-05-26T05:42:38.154027Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers==4.20.0\n!pip install keras_nlp==0.3.0\n!pip install datasets\n!pip install huggingface-hub\n!pip install nltk\n!pip install rouge-score\ncls()","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:42:38.158536Z","iopub.execute_input":"2023-05-26T05:42:38.159094Z","iopub.status.idle":"2023-05-26T05:43:54.923736Z","shell.execute_reply.started":"2023-05-26T05:42:38.159064Z","shell.execute_reply":"2023-05-26T05:43:54.922555Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:43:54.925689Z","iopub.execute_input":"2023-05-26T05:43:54.926063Z","iopub.status.idle":"2023-05-26T05:44:04.819894Z","shell.execute_reply.started":"2023-05-26T05:43:54.926027Z","shell.execute_reply":"2023-05-26T05:44:04.818900Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport logging\n\nimport nltk\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Only log error messages\ntf.get_logger().setLevel(logging.ERROR)\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:04.822512Z","iopub.execute_input":"2023-05-26T05:44:04.823770Z","iopub.status.idle":"2023-05-26T05:44:05.826070Z","shell.execute_reply.started":"2023-05-26T05:44:04.823734Z","shell.execute_reply":"2023-05-26T05:44:05.824898Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# The percentage of the dataset you want to split as train and test\nTRAIN_TEST_SPLIT = 0.1\n\nMAX_INPUT_LENGTH = 1024  # Maximum length of the input to the model\nMIN_TARGET_LENGTH = 5  # Minimum length of the output by the model\nMAX_TARGET_LENGTH = 128  # Maximum length of the output by the model\nBATCH_SIZE = 1  # Batch-size for training our model\nLEARNING_RATE = 3e-5  # Learning-rate for training our model\nMAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n\n# This notebook is built on the facebook/bart-large-cnn checkpoint from the Hugging Face Model Hub\nMODEL_CHECKPOINT = \"facebook/bart-large-cnn\"","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:05.827368Z","iopub.execute_input":"2023-05-26T05:44:05.829327Z","iopub.status.idle":"2023-05-26T05:44:05.835020Z","shell.execute_reply.started":"2023-05-26T05:44:05.829286Z","shell.execute_reply":"2023-05-26T05:44:05.833873Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Define Tokenizer, Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:05.836495Z","iopub.execute_input":"2023-05-26T05:44:05.836852Z","iopub.status.idle":"2023-05-26T05:44:08.831984Z","shell.execute_reply.started":"2023-05-26T05:44:05.836820Z","shell.execute_reply":"2023-05-26T05:44:08.831018Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cf7863c3fd2426fb8ddb09627239ef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ddf3d24c09430ea06a9a3d8755044e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb304cab38cb487bbd2f9ce70127e211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d6910a154c4e10ace44ffca2718286"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TFBartForConditionalGeneration\n\n# Load and compile our model\nmodel = TFBartForConditionalGeneration.from_pretrained(MODEL_CHECKPOINT)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:08.833461Z","iopub.execute_input":"2023-05-26T05:44:08.833832Z","iopub.status.idle":"2023-05-26T05:44:48.056063Z","shell.execute_reply.started":"2023-05-26T05:44:08.833798Z","shell.execute_reply":"2023-05-26T05:44:48.055045Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9339f71fc026461bb46aa8097dfaba3f"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n\nAll the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"dataset_dir = \"/kaggle/input/e-waste-article-summarization/e-waste-summarization-dataset.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:48.058282Z","iopub.execute_input":"2023-05-26T05:44:48.058675Z","iopub.status.idle":"2023-05-26T05:44:48.065006Z","shell.execute_reply.started":"2023-05-26T05:44:48.058639Z","shell.execute_reply":"2023-05-26T05:44:48.064148Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('csv', data_files=dataset_dir)\ndataset = dataset['train'].train_test_split(test_size=TRAIN_TEST_SPLIT)\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:48.066311Z","iopub.execute_input":"2023-05-26T05:44:48.066724Z","iopub.status.idle":"2023-05-26T05:44:49.596760Z","shell.execute_reply.started":"2023-05-26T05:44:48.066692Z","shell.execute_reply":"2023-05-26T05:44:49.595871Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-45fb6e5057ab3895/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d26bdc1e62422697d6f8c635a9e58d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adce6152ab10481aab5f8f951a78e668"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-45fb6e5057ab3895/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97899d41a09249bf8881f597f57e3441"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Text', 'Summary'],\n        num_rows: 145\n    })\n    test: Dataset({\n        features: ['Text', 'Summary'],\n        num_rows: 17\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = examples[\"Text\"]\n    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"Summary\"], max_length=MAX_TARGET_LENGTH, truncation=True\n        )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:49.600630Z","iopub.execute_input":"2023-05-26T05:44:49.601515Z","iopub.status.idle":"2023-05-26T05:44:49.608020Z","shell.execute_reply.started":"2023-05-26T05:44:49.601458Z","shell.execute_reply":"2023-05-26T05:44:49.606964Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:49.609460Z","iopub.execute_input":"2023-05-26T05:44:49.609874Z","iopub.status.idle":"2023-05-26T05:44:50.492213Z","shell.execute_reply.started":"2023-05-26T05:44:49.609842Z","shell.execute_reply":"2023-05-26T05:44:50.491315Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91c5b9753df442238f1d606c2625f598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2bfc1cfc4104cfa82e9dd5cbed54370"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:50.493861Z","iopub.execute_input":"2023-05-26T05:44:50.494520Z","iopub.status.idle":"2023-05-26T05:44:50.501000Z","shell.execute_reply.started":"2023-05-26T05:44:50.494484Z","shell.execute_reply":"2023-05-26T05:44:50.500024Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Text', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 145\n    })\n    test: Dataset({\n        features: ['Text', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 17\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# len(tokenized_datasets['train']['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:50.502513Z","iopub.execute_input":"2023-05-26T05:44:50.503143Z","iopub.status.idle":"2023-05-26T05:44:50.515765Z","shell.execute_reply.started":"2023-05-26T05:44:50.503111Z","shell.execute_reply":"2023-05-26T05:44:50.514521Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:50.518822Z","iopub.execute_input":"2023-05-26T05:44:50.519094Z","iopub.status.idle":"2023-05-26T05:44:50.527100Z","shell.execute_reply.started":"2023-05-26T05:44:50.519071Z","shell.execute_reply":"2023-05-26T05:44:50.525937Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    batch_size=BATCH_SIZE,\n    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n    shuffle=True,\n    collate_fn=data_collator,\n)\n\ntest_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n    batch_size=BATCH_SIZE,\n    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n    shuffle=False,\n    collate_fn=data_collator,\n)\n\ngeneration_dataset = (\n    tokenized_datasets[\"test\"]\n    .shuffle()\n#     .select(list(range(200)))\n    .to_tf_dataset(\n        batch_size=BATCH_SIZE,\n        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n        shuffle=False,\n        collate_fn=data_collator,\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:50.528633Z","iopub.execute_input":"2023-05-26T05:44:50.529048Z","iopub.status.idle":"2023-05-26T05:44:50.787517Z","shell.execute_reply.started":"2023-05-26T05:44:50.529018Z","shell.execute_reply":"2023-05-26T05:44:50.786444Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import keras_nlp\n\nrouge_l = keras_nlp.metrics.RougeL()\n\ndef metric_fn(eval_predictions):\n    predictions, labels = eval_predictions\n    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    for label in labels:\n        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = rouge_l(decoded_labels, decoded_predictions)\n    # We will print only the F1 score, you can use other aggregation metrics as well\n    result = {\"RougeL\": result[\"f1_score\"]}\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:50.789021Z","iopub.execute_input":"2023-05-26T05:44:50.789370Z","iopub.status.idle":"2023-05-26T05:44:51.320740Z","shell.execute_reply.started":"2023-05-26T05:44:50.789337Z","shell.execute_reply":"2023-05-26T05:44:51.319822Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import KerasMetricCallback\n\nmetric_callback = KerasMetricCallback(\n    metric_fn, eval_dataset=generation_dataset, predict_with_generate=True\n)\n\ncallbacks = [metric_callback]","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:51.322207Z","iopub.execute_input":"2023-05-26T05:44:51.322560Z","iopub.status.idle":"2023-05-26T05:44:51.350606Z","shell.execute_reply.started":"2023-05-26T05:44:51.322526Z","shell.execute_reply":"2023-05-26T05:44:51.349799Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Lower learning rates are often better for fine-tuning transformers\nmodel.compile(optimizer=Adam(LEARNING_RATE))\n\nmodel.fit(train_dataset, validation_data=test_dataset, epochs=MAX_EPOCHS, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T05:44:51.352031Z","iopub.execute_input":"2023-05-26T05:44:51.352332Z","iopub.status.idle":"2023-05-26T06:12:27.682141Z","shell.execute_reply.started":"2023-05-26T05:44:51.352303Z","shell.execute_reply":"2023-05-26T06:12:27.681216Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"},{"name":"stdout","text":"145/145 [==============================] - 1602s 10s/step - loss: 1.7057 - val_loss: 1.5469 - RougeL: 0.2789\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78d2e004ae30>"},"metadata":{}}]},{"cell_type":"code","source":"text = dataset['test'][0]['Text']","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:18:41.976347Z","iopub.execute_input":"2023-05-26T06:18:41.977067Z","iopub.status.idle":"2023-05-26T06:18:41.982298Z","shell.execute_reply.started":"2023-05-26T06:18:41.977032Z","shell.execute_reply":"2023-05-26T06:18:41.981245Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:19:31.101392Z","iopub.execute_input":"2023-05-26T06:19:31.101785Z","iopub.status.idle":"2023-05-26T06:19:31.109269Z","shell.execute_reply.started":"2023-05-26T06:19:31.101755Z","shell.execute_reply":"2023-05-26T06:19:31.107861Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"start_time = timer(None)\ninput_ids = tokenizer.encode(text, return_tensors=\"tf\", truncation=True)\ngenerated_sequence = model.generate(input_ids=input_ids)\noutput_text = tokenizer.decode(generated_sequence.numpy().squeeze(), skip_special_tokens=True)\ntimer(start_time)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:20:11.183254Z","iopub.execute_input":"2023-05-26T06:20:11.183636Z","iopub.status.idle":"2023-05-26T06:21:31.761560Z","shell.execute_reply.started":"2023-05-26T06:20:11.183605Z","shell.execute_reply":"2023-05-26T06:21:31.760512Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\n Time taken: 0 hours 1 minutes and 20.57 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"output_text","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:21:31.763327Z","iopub.execute_input":"2023-05-26T06:21:31.764265Z","iopub.status.idle":"2023-05-26T06:21:31.770353Z","shell.execute_reply.started":"2023-05-26T06:21:31.764230Z","shell.execute_reply":"2023-05-26T06:21:31.769368Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'E-waste is a growing waste problem around the world, with over 49 million tons of electronic waste discarded in 2016, with a projected 57 million tons by 2021. To address this issue, there are several steps your company can take, including embracing cloud services like cloud storage, donating electronics you no longer use, checking manufacturers for recycling programs, and ensuring electronic waste disposal is properly disposed of. Certified e-Waste disposal companies can help solve electronic waste management issues, including transportation of large quantities, collection sites, and drop-off facilities that accept electronic waste, as well as quick disposal facilities. The California Department of Resources, known as CalRecycleRecycling and Recovery,'"},"metadata":{}}]},{"cell_type":"code","source":"true_label = dataset['test'][0]['Summary']\ntrue_label","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:22:40.218964Z","iopub.execute_input":"2023-05-26T06:22:40.219560Z","iopub.status.idle":"2023-05-26T06:22:40.228652Z","shell.execute_reply.started":"2023-05-26T06:22:40.219513Z","shell.execute_reply":"2023-05-26T06:22:40.227389Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'To improve electronic waste management, companies can take four simple steps. Firstly, embracing cloud services reduces the need for physical electronic devices like servers and circuit boards. Secondly, donating functioning electronics to organizations that refurbish and distribute them to those in need helps keep devices out of landfills. Thirdly, checking with manufacturers for recycling programs allows for proper disposal and potential discounts on future purchases. Lastly, ensuring that electronic waste is properly disposed of by partnering with a certified e-waste disposal company streamlines the process and ensures compliance with regulations. These actions contribute to reducing the amount of e-waste generated and promote responsible and sustainable practices.'"},"metadata":{}}]},{"cell_type":"code","source":"result = rouge_l(output_text, true_label)\n# We will print only the F1 score, you can use other aggregation metrics as well\nresult = {\"RougeL\": result[\"f1_score\"]}\nresult","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:22:49.579637Z","iopub.execute_input":"2023-05-26T06:22:49.581765Z","iopub.status.idle":"2023-05-26T06:22:49.609919Z","shell.execute_reply.started":"2023-05-26T06:22:49.581720Z","shell.execute_reply":"2023-05-26T06:22:49.608885Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'RougeL': <tf.Tensor: shape=(), dtype=float32, numpy=0.27936164>}"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:12:27.683729Z","iopub.execute_input":"2023-05-26T06:12:27.684087Z","iopub.status.idle":"2023-05-26T06:12:28.749971Z","shell.execute_reply.started":"2023-05-26T06:12:27.684055Z","shell.execute_reply":"2023-05-26T06:12:28.748604Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Fri May 26 06:12:28 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   42C    P0    38W / 250W |   9167MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"saved_model_finetuned\"\n\nmodel.save_pretrained(path, from_tf=True)\ntokenizer.save_pretrained(path+\"/tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:24:09.827908Z","iopub.execute_input":"2023-05-26T06:24:09.828289Z","iopub.status.idle":"2023-05-26T06:24:15.246537Z","shell.execute_reply.started":"2023-05-26T06:24:09.828260Z","shell.execute_reply":"2023-05-26T06:24:15.245672Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('saved_model_finetuned/tokenizer/tokenizer_config.json',\n 'saved_model_finetuned/tokenizer/special_tokens_map.json',\n 'saved_model_finetuned/tokenizer/vocab.json',\n 'saved_model_finetuned/tokenizer/merges.txt',\n 'saved_model_finetuned/tokenizer/added_tokens.json',\n 'saved_model_finetuned/tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"import zipfile\nimport os\n\noutput_dir = \"fine_tuned_model.zip\"\n\nwith zipfile.ZipFile(output_dir, 'w') as z:\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            z.write(file_path, file_path[len(folder_path):])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('completed')","metadata":{"execution":{"iopub.status.busy":"2023-05-26T06:31:21.761219Z","iopub.execute_input":"2023-05-26T06:31:21.762112Z","iopub.status.idle":"2023-05-26T06:31:21.767649Z","shell.execute_reply.started":"2023-05-26T06:31:21.762080Z","shell.execute_reply":"2023-05-26T06:31:21.766617Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"completed\n","output_type":"stream"}]}]}